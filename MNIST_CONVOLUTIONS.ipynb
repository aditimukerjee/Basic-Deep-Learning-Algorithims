{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "MNIST CONVOLUTIONS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4LKVM2HEqWf"
      },
      "source": [
        "MNIST USING CONVOLUTIONS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYRzT-i2EqWp"
      },
      "source": [
        "This is perfect for computer vision, because often it's features that can get highlighted like this that distinguish one item for another, and the amount of information needed is then much less...because you'll just train on the highlighted features.\n",
        "\n",
        "That's the concept of Convolutional Neural Networks. Add some layers to do convolution before you have the dense layers, and then the information going to the dense layers is more focussed, and possibly more accurate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiZlkMZ9EqWq"
      },
      "source": [
        "# MY CALLBACKS\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>=0.998):\n",
        "      print(\"\\nReached 998% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYyhNo9gEqWr",
        "outputId": "0cecead3-76d7-4f1d-81f7-484c5f1128dc"
      },
      "source": [
        "#importing the libary\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "#importing the mnist dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "#training images and test images\n",
        "training_images=training_images.reshape(60000, 28, 28, 1) #reshape\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1) #reshape\n",
        "#You'll notice that there's a bit of a change here in that the training data needed to be reshaped.\n",
        "#That's because the first convolution expects a single tensor containing everything, so instead of 60,000 28x28x1 \n",
        "#items in a list, we have a single 4D list that is 60,000x28x28x1, and the same for the test images.\n",
        "test_images=test_images/255.0\n",
        "\n",
        "#my call backs\n",
        "callbacks = myCallback()\n",
        "#defining the models\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(256, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "#You'll follow the Convolution with a MaxPooling layer which is then designed to compress the image, \n",
        "#while maintaining the content of the features that were highlighted by the convlution. By specifying (2,2) for the MaxPooling, the effect is to quarter the size of the image. Without going into too much detail here, the idea is that it creates a 2x2 array of pixels, and picks the biggest one, thus turning 4 pixels into 1.\n",
        "\n",
        "#compiling the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "#model summary\n",
        "model.summary()\n",
        "#model.summary() to see the size and shape of the network\n",
        "\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=20, callbacks=[callbacks])\n",
        "\n",
        "print(\"------------------------------------------------------------------\")\n",
        "print(\"The performance of test dataset is as follows\")\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 256)       2560      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 43264)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               11075840  \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 11,080,970\n",
            "Trainable params: 11,080,970\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 274s 146ms/step - loss: 0.2144 - acc: 0.9318\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 272s 145ms/step - loss: 0.0358 - acc: 0.9892\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 270s 144ms/step - loss: 0.0186 - acc: 0.9939\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 270s 144ms/step - loss: 0.0136 - acc: 0.9955\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 270s 144ms/step - loss: 0.0079 - acc: 0.9974\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 269s 143ms/step - loss: 0.0057 - acc: 0.9980\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 268s 143ms/step - loss: 0.0056 - acc: 0.9980\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 268s 143ms/step - loss: 0.0037 - acc: 0.9988\n",
            "\n",
            "Reached 998% accuracy so cancelling training!\n",
            "------------------------------------------------------------------\n",
            "The performance of test dataset is as follows\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.0564 - acc: 0.9869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTCUguLuNIDo"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keN_kr86EqWt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}